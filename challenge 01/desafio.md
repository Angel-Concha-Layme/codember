## Descripci√≥n del Reto üïµÔ∏è‚Äç‚ôÇÔ∏èüîç

### Objetivo üéØ

Un esp√≠a ha estado transmitiendo mensajes secretos que necesitamos descifrar. Estos mensajes consisten en una serie de palabras codificadas, y tu labor es desarrollar un algoritmo capaz de analizar estos mensajes y encontrar los patrones ocultos.

### Especificaciones del Programa üìù

El programa debe realizar lo siguiente:

- **Analizar el Texto**: Procesar una cadena de texto que contiene palabras separadas por espacios. Por ejemplo:

    gato perro perro coche Gato peRRo sol


- **Normalizar May√∫sculas y Min√∫sculas**: Identificar palabras sin importar la diferencia entre may√∫sculas y min√∫sculas, trat√°ndolas como iguales.

- **Contabilizar Apariciones**: Calcular la frecuencia con la que cada palabra √∫nica aparece en el mensaje.

- **Formato de Salida**: Generar una cadena de texto que contenga cada palabra seguida del n√∫mero de veces que aparece. La cadena debe mantener el orden de la primera aparici√≥n de cada palabra en el mensaje original. Por ejemplo:


    gato2perro3coche1sol1


### Ejemplos Adicionales üìä

Aqu√≠ se muestran algunos ejemplos m√°s del funcionamiento esperado del programa:

- Entrada: `llaveS casa CASA casa llaves`
Salida: `llaves2casa3`

- Entrada: `taza ta za taza`
Salida: `taza2ta1za1`

- Entrada: `casas casa casasas`
Salida: `casas1casa1casas1`



## Soluci√≥n del Reto ü§ì
Este problema se puede solucionar de diversas maneras, pero una estrategia particularmente eficaz para lidiar con el procesamiento de texto y la agregaci√≥n de datos es el modelo MapReduce. Este modelo se alinea bien con tareas que implican la manipulaci√≥n y conteo de elementos como las palabras en un texto. Aunque nuestra aplicaci√≥n no requiere la escala para la cual MapReduce fue originalmente dise√±ado, adoptar este patr√≥n ofrece claridad conceptual, potencial de escalabilidad y una soluci√≥n estructurada que podr√≠a ser extendida a entornos de procesamiento distribuido si fuera necesario.

### Por qu√© MapReduce es Adecuado
MapReduce es un paradigma poderoso cuando necesitamos analizar grandes cantidades de datos y extraer informaci√≥n valiosa de ellos. En el caso de los mensajes encriptados de un esp√≠a, la simplicidad de paralelizaci√≥n, escalabilidad, tolerancia a fallos y el manejo eficiente de pares clave-valor lo hacen una elecci√≥n acertada incluso para conjuntos de datos menos voluminosos.



### Fases del MapReduce

La soluci√≥n adopta el modelo de MapReduce para dividir el proceso de an√°lisis del texto en dos fases principales, cada una con sus propias responsabilidades y operaciones espec√≠ficas. A continuaci√≥n, detallo cada fase y explico con mayor profundidad las tareas involucradas:

#### Fase de Mapeo (Map Phase)

En la fase de mapeo, el objetivo es preparar los datos para el proceso de agregaci√≥n. Aqu√≠ se realiza el trabajo preliminar de organizar la informaci√≥n de entrada de tal manera que pueda ser procesada eficientemente en la siguiente fase.

- **Tokenizaci√≥n**: Esta operaci√≥n implica escanear el texto de entrada y separarlo en elementos individuales, llamados tokens, basados en un criterio definido, que en este caso es el espacio en blanco entre palabras. Cada token representa una palabra que ser√° sujeto de conteo.

- **Normalizaci√≥n**: Una vez que tenemos los tokens, se procede a normalizarlos. Esto significa que se eliminan las diferencias de formato que no son relevantes para el conteo, como las may√∫sculas y min√∫sculas. Al convertir todos los tokens a min√∫sculas, aseguramos que 'Palabra', 'palabra' y 'PALABRA' se cuenten como la misma entidad.

- **Contabilizaci√≥n**: Finalmente, cada token normalizado se contabiliza. Se crea un par clave-valor donde la clave es la palabra normalizada y el valor es el n√∫mero de veces que esa palabra ha aparecido hasta el momento. Este proceso se lleva a cabo utilizando una estructura de datos que mantiene el orden de inserci√≥n (en Java, `LinkedHashMap`), para que podamos luego reconstruir el mensaje en el mismo orden en que las palabras aparecieron originalmente.

```java 
    public static class Mapper {
        public Map<String, Integer> map(String input) {
            Map<String, Integer> wordCount = new LinkedHashMap<>();
            String[] words = input.split(" ");
            for (String word : words) {
                word = word.toLowerCase();
                wordCount.put(word, wordCount.getOrDefault(word, 0) + 1);
            }
            return wordCount;
        }
    }
```



#### Fase de Reducci√≥n (Reduce Phase)

La fase de reducci√≥n toma la salida del mapeo, que es un conjunto de pares clave-valor, y los combina para producir el resultado final.

- **Agregaci√≥n**: En esta etapa, procesamos la colecci√≥n de pares clave-valor para consolidar los resultados. Dado que el proceso de mapeo ya ha contabilizado las apariciones de cada palabra, en realidad no hay una 'agregaci√≥n' en el sentido tradicional de combinar m√∫ltiples valores. En su lugar, lo que hacemos es prepararnos para la salida final al asegurarnos de que tenemos un conteo completo y final para cada palabra.

- **Construcci√≥n de la Salida**: Con los conteos finales en mano, construimos la cadena de salida. Iteramos sobre el `LinkedHashMap`, que nos da las palabras en el orden de su primera aparici√≥n, y para cada palabra, anexamos su contador al final. Este proceso genera una cadena que es la representaci√≥n agregada del mensaje original, con el formato requerido de "palabraconteo".

```java
    public static class Reducer {
        public String reduce(Map<String, Integer> mappedData) {
            StringBuilder result = new StringBuilder();
            for (Map.Entry<String, Integer> entry : mappedData.entrySet()) {
                result.append(entry.getKey()).append(entry.getValue());
            }
            return result.toString();
        }
    }
```





Cada una de estas fases se dise√±√≥ para operar de manera eficiente sobre el conjunto de datos y, aunque en esta implementaci√≥n trabajan de manera secuencial en un solo hilo, est√°n conceptualmente preparadas para ser escaladas a un entorno distribuido donde la tokenizaci√≥n y la contabilizaci√≥n podr√≠an ocurrir en paralelo a trav√©s de m√∫ltiples nodos en un cl√∫ster, y la reducci√≥n se encargar√≠a de unir los resultados intermedios en la respuesta final.